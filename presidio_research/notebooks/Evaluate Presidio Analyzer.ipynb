{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_evaluator.data_generator import read_synth_dataset\n",
    "from presidio_evaluator.evaluation import ModelError, Evaluator\n",
    "from presidio_evaluator.models import BaseModel, PresidioAnalyzerWrapper\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Presidio Analyzer\n",
    "This notebook runs the PresidioAnalyzerEvaluator class on top of synthetic data.\n",
    "\n",
    "One can perform the following changes:\n",
    "1. Replace the synthetic data creation with real data or with other type of synthetic data\n",
    "2. Adapt the Presidio `AnalyzerEngine` to a specific engine with a different set of recognizers or configured to be used on different languages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Read dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_samples = read_synth_dataset(\"../data/synth_dataset.txt\")\n",
    "print(\"Read {} samples\".format(len(input_samples)))\n",
    "input_samples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "count_per_entity = Counter([span.entity_type for span in flatten([input_sample.spans for input_sample in input_samples])])\n",
    "count_per_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Match the dataset's entity names with Presidio's entity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidio_entities_map = {\n",
    "    \"PERSON\": \"PERSON\",\n",
    "    \"EMAIL_ADDRESS\": \"EMAIL_ADDRESS\",\n",
    "    \"CREDIT_CARD\": \"CREDIT_CARD\",\n",
    "    \"FIRST_NAME\": \"PERSON\",\n",
    "    \"PHONE_NUMBER\": \"PHONE_NUMBER\",\n",
    "    \"BIRTHDAY\": \"DATE_TIME\",\n",
    "    \"DATE_TIME\": \"DATE_TIME\",\n",
    "    \"DOMAIN\": \"DOMAIN\",\n",
    "    \"CITY\": \"LOCATION\",\n",
    "    \"ADDRESS\": \"LOCATION\",\n",
    "    \"NATIONALITY\": \"LOCATION\",\n",
    "    \"LOCATION\": \"LOCATION\",\n",
    "    \"IBAN\": \"IBAN_CODE\",\n",
    "    \"URL\": \"DOMAIN_NAME\",\n",
    "    \"US_SSN\": \"US_SSN\",\n",
    "    \"IP_ADDRESS\": \"IP_ADDRESS\",\n",
    "    \"ORGANIZATION\": \"ORG\",\n",
    "    \"TITLE\" : \"O\", # skipping evaluation of titles\n",
    "    \"O\": \"O\",\n",
    "}\n",
    "\n",
    "new_list = Evaluator.align_entity_types(input_samples, presidio_entities_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Recalculate statistics on updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recheck counter\n",
    "count_per_entity_new = Counter([span.entity_type for span in flatten([input_sample.spans for input_sample in new_list])])\n",
    "count_per_entity_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Run the presidio-evaluator framework with Presidio's API as the 'model' at test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidio = PresidioAnalyzerWrapper(entities_to_keep=list(count_per_entity_new.keys()))\n",
    "evaluator = Evaluator(model=presidio)\n",
    "evaluted_samples = evaluator.evaluate_all(new_list[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Extract statistics\n",
    "- Presicion, recall and F measure are calculated based on a PII/Not PII binary classification per token.\n",
    "- Specific entity recall and precision are calculated on the specific PII entity level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluator.calculate_score(evaluted_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G. Analyze wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = evaluation_result.model_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelError.most_common_fp_tokens(errors,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fps_df = ModelError.get_fps_dataframe(errors,entity='PERSON')\n",
    "if fps_df is not None:\n",
    "    fps_df[['full_text','token','prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_df = ModelError.get_fns_dataframe(errors,entity='PERSON')\n",
    "fns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "presidio-research",
   "language": "python",
   "name": "presidio-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}